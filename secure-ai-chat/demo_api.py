#!/usr/bin/env python3
"""
ãƒ‡ãƒ¢ç”¨ç°¡æ˜“APIã‚µãƒ¼ãƒãƒ¼ - ãŠå®¢æ§˜ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç”¨
FastAPIä¸è¦ã®ã‚·ãƒ³ãƒ—ãƒ«ç‰ˆ + å®Ÿéš›ã®OpenAI APIé€£æº
"""

import json
import time
import uuid
import os
import asyncio
from http.server import HTTPServer, BaseHTTPRequestHandler
from urllib.parse import urlparse, parse_qs
import threading
from datetime import datetime
from dotenv import load_dotenv

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

# OpenAI APIè¨­å®š
try:
    from openai import OpenAI
    OPENAI_CLIENT = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
    OPENAI_AVAILABLE = bool(os.getenv('OPENAI_API_KEY'))
    print(f"ğŸ”‘ OpenAI API: {'åˆ©ç”¨å¯èƒ½' if OPENAI_AVAILABLE else 'æœªè¨­å®šï¼ˆãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œï¼‰'}")
except ImportError:
    OPENAI_CLIENT = None
    OPENAI_AVAILABLE = False
    print("âš ï¸ OpenAI ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œã—ã¾ã™ã€‚")

# ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰
templates_storage = {}

def initialize_demo_templates():
    """ãƒ‡ãƒ¢ç”¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’åˆæœŸåŒ–"""
    demo_templates = [
        {
            "id": "1",
            "name": "ğŸ“Š ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†ã‚¢ãƒ‰ãƒã‚¤ã‚¹",
            "description": "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé€²è¡Œç®¡ç†ã®ãŸã‚ã®å°‚é–€çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›",
            "category": "ãƒ“ã‚¸ãƒã‚¹",
            "system_prompt": "ä»¥ä¸‹ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ã¤ã„ã¦ã€é€²è¡Œç®¡ç†ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ãã ã•ã„ï¼š\n\nãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå: {project_name}\næœŸé–“: {duration}\nãƒãƒ¼ãƒ è¦æ¨¡: {team_size}",
            "variables": [
                {"name": "project_name", "description": "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå", "type": "text", "required": True},
                {"name": "duration", "description": "æœŸé–“", "type": "text", "required": True},
                {"name": "team_size", "description": "ãƒãƒ¼ãƒ è¦æ¨¡", "type": "text", "required": True}
            ],
            "example_input": "æ–°ã—ã„ECã‚µã‚¤ãƒˆã®é–‹ç™ºãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ã¤ã„ã¦ç®¡ç†ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ãŠé¡˜ã„ã—ã¾ã™",
            "example_output": "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†ã®è¦³ç‚¹ã‹ã‚‰ã€ä»¥ä¸‹ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ã—ã¾ã™...",
            "created_at": datetime.now().isoformat(),
            "updated_at": datetime.now().isoformat(),
            "is_active": True
        },
        {
            "id": "2", 
            "name": "ğŸ”’ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ¤œè¨",
            "description": "ã‚·ã‚¹ãƒ†ãƒ ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¯¾ç­–ã‚’å°‚é–€çš„ã«è©•ä¾¡ãƒ»ææ¡ˆ",
            "category": "æŠ€è¡“",
            "system_prompt": "{system_name}ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¯¾ç­–ã«ã¤ã„ã¦æ¤œè¨ã—ãŸã„ã§ã™ã€‚ç‰¹ã«{concern_area}ã®è¦³ç‚¹ã‹ã‚‰è©•ä¾¡ãƒ»ææ¡ˆã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚",
            "variables": [
                {"name": "system_name", "description": "ã‚·ã‚¹ãƒ†ãƒ å", "type": "text", "required": True},
                {"name": "concern_area", "description": "é‡ç‚¹çš„ã«ç¢ºèªã—ãŸã„é ˜åŸŸ", "type": "text", "required": True}
            ],
            "example_input": "ã‚¯ãƒ©ã‚¦ãƒ‰ç’°å¢ƒã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã«ã¤ã„ã¦æ¤œè¨ã—ã¦ãã ã•ã„",
            "example_output": "ã‚¯ãƒ©ã‚¦ãƒ‰ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã«ã¤ã„ã¦ã€ä»¥ä¸‹ã®è¦³ç‚¹ã‹ã‚‰è©•ä¾¡ã—ã¾ã™...",
            "created_at": datetime.now().isoformat(),
            "updated_at": datetime.now().isoformat(),
            "is_active": True
        },
        {
            "id": "3",
            "name": "ğŸ“§ ãƒ“ã‚¸ãƒã‚¹ãƒ¡ãƒ¼ãƒ«ä½œæˆ",
            "description": "ä¸å¯§ã§åŠ¹æœçš„ãªãƒ“ã‚¸ãƒã‚¹ãƒ¡ãƒ¼ãƒ«ã‚’è‡ªå‹•ç”Ÿæˆ",
            "category": "ãƒ“ã‚¸ãƒã‚¹", 
            "system_prompt": "ä»¶å: {subject}ã«ã¤ã„ã¦\n\n{recipient}æ§˜\n\nã„ã¤ã‚‚ãŠä¸–è©±ã«ãªã£ã¦ãŠã‚Šã¾ã™ã€‚\n{sender_name}ã§ã™ã€‚\n\n{main_content}\n\nä½•ã‹ã”ä¸æ˜ãªç‚¹ãŒã”ã–ã„ã¾ã—ãŸã‚‰ã€\nãŠæ°—è»½ã«ãŠå£°ã‹ã‘ãã ã•ã„ã€‚\n\nã‚ˆã‚ã—ããŠé¡˜ã„ã„ãŸã—ã¾ã™ã€‚",
            "variables": [
                {"name": "subject", "description": "ä»¶å", "type": "text", "required": True},
                {"name": "recipient", "description": "å®›å…ˆ", "type": "text", "required": True},
                {"name": "sender_name", "description": "é€ä¿¡è€…å", "type": "text", "required": True},
                {"name": "main_content", "description": "ãƒ¡ã‚¤ãƒ³å†…å®¹", "type": "textarea", "required": True}
            ],
            "example_input": "æ˜æ—¥ã®ä¼šè­°ã®è³‡æ–™ã«ã¤ã„ã¦é€£çµ¡ã—ãŸã„",
            "example_output": "ä»¶å: ä¼šè­°è³‡æ–™ã«ã¤ã„ã¦\n\nç”°ä¸­æ§˜\n\nã„ã¤ã‚‚ãŠä¸–è©±ã«ãªã£ã¦ãŠã‚Šã¾ã™...",
            "created_at": datetime.now().isoformat(),
            "updated_at": datetime.now().isoformat(),
            "is_active": True
        }
    ]
    
    for template in demo_templates:
        templates_storage[template["id"]] = template
    
    print(f"ğŸ“ ãƒ‡ãƒ¢ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåˆæœŸåŒ–å®Œäº†: {len(demo_templates)}ä»¶")

class DemoAPIHandler(BaseHTTPRequestHandler):
    def do_OPTIONS(self):
        """CORS preflightå¯¾å¿œ"""
        self.send_response(200)
        self.send_header('Access-Control-Allow-Origin', '*')
        self.send_header('Access-Control-Allow-Methods', 'GET, POST, OPTIONS')
        self.send_header('Access-Control-Allow-Headers', 'Content-Type, Authorization')
        self.end_headers()

    def do_GET(self):
        """GETãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†"""
        parsed_path = urlparse(self.path)
        
        if parsed_path.path == '/health':
            self.send_json_response({"status": "healthy", "timestamp": datetime.now().isoformat()})
        elif parsed_path.path == '/api/templates':
            print("ğŸ“ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä¸€è¦§å–å¾—ãƒªã‚¯ã‚¨ã‚¹ãƒˆ")
            # ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‹ã‚‰ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å–å¾—
            active_templates = [
                template for template in templates_storage.values() 
                if template.get('is_active', True)
            ]
            # æ›´æ–°æ—¥æ™‚ã§ã‚½ãƒ¼ãƒˆ
            active_templates.sort(key=lambda x: x.get('updated_at', ''), reverse=True)
            print(f"ğŸ“‹ ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ: {len(active_templates)}ä»¶")
            self.send_json_response(active_templates)
        elif parsed_path.path == '/api/models':
            # åˆ©ç”¨å¯èƒ½ãªAIãƒ¢ãƒ‡ãƒ«
            models = [
                {"id": "gpt-3.5-turbo", "name": "GPT-3.5 Turbo", "available": True},
                {"id": "gpt-4", "name": "GPT-4", "available": True},
                {"id": "gpt-4o", "name": "GPT-4o", "available": True}
            ]
            self.send_json_response(models)
        elif parsed_path.path == '/api/dashboard/kpi':
            # ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰KPIãƒ‡ãƒ¼ã‚¿
            kpi_data = {
                "totalMessages": 12847,
                "activeUsers": 156,
                "monthlyCost": 45230,
                "avgResponse": 1.2,
                "trends": {
                    "messages": "+15.2%",
                    "users": "+8.7%",
                    "cost": "+2.1%",
                    "response": "-0.3ç§’"
                }
            }
            self.send_json_response(kpi_data)
        elif parsed_path.path == '/api/dashboard/usage':
            # ä½¿ç”¨é‡ãƒ‡ãƒ¼ã‚¿
            usage_data = {
                "daily": [120, 135, 98, 145, 167, 134, 156, 178, 145, 189, 156, 167, 134, 145, 178, 156, 134, 189, 167, 145, 156, 178, 134, 167, 145, 189, 156, 178, 167, 145],
                "teams": {
                    "sales": {"messages": 4230, "efficiency_hours": 950, "cost": 18450},
                    "dev": {"messages": 6180, "efficiency_hours": 1380, "cost": 19680},
                    "marketing": {"messages": 2437, "efficiency_hours": 510, "cost": 7100}
                }
            }
            self.send_json_response(usage_data)
        elif parsed_path.path == '/api/dashboard/audit':
            # ç›£æŸ»ãƒ­ã‚°
            audit_logs = [
                {
                    "timestamp": "2024-01-15 14:35:22",
                    "action": "ãƒ¦ãƒ¼ã‚¶ãƒ¼æ¨©é™å¤‰æ›´",
                    "detail": "ç”°ä¸­å¤ªéƒã®æ¨©é™ã‚’ç®¡ç†è€…ã«å¤‰æ›´",
                    "user": "ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…"
                },
                {
                    "timestamp": "2024-01-15 13:20:15", 
                    "action": "æ–°è¦ãƒãƒ¼ãƒ ä½œæˆ",
                    "detail": "ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°éƒ¨ãƒãƒ¼ãƒ ã‚’ä½œæˆ",
                    "user": "ä½è—¤èŠ±å­"
                },
                {
                    "timestamp": "2024-01-15 11:45:08",
                    "action": "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®šå¤‰æ›´", 
                    "detail": "äºŒè¦ç´ èªè¨¼ã‚’æœ‰åŠ¹åŒ–",
                    "user": "ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…"
                }
            ]
            self.send_json_response(audit_logs)
        else:
            self.send_error(404, "Not Found")

    def do_POST(self):
        """POSTãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†"""
        parsed_path = urlparse(self.path)
        
        if parsed_path.path == '/api/chat':
            # ãƒãƒ£ãƒƒãƒˆAPIï¼ˆãƒ‡ãƒ¢å¿œç­”ï¼‰
            content_length = int(self.headers['Content-Length'])
            post_data = self.rfile.read(content_length)
            
            try:
                request_data = json.loads(post_data.decode('utf-8'))
                message = request_data.get('message', '')
                model = request_data.get('model', 'gpt-3.5-turbo')
                
                print(f"ğŸ’¬ ãƒãƒ£ãƒƒãƒˆãƒªã‚¯ã‚¨ã‚¹ãƒˆ: {message[:50]}...")
                
                # å®Ÿéš›ã®OpenAI APIã‚’æœ€åˆã«è©¦ã™
                ai_response = self.get_real_ai_response(message, model)
                
                if ai_response:
                    print("âœ… å®Ÿéš›ã®AI APIã§å¿œç­”")
                    self.send_json_response(ai_response)
                else:
                    print("âš ï¸ ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ã§å¿œç­”")
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šãƒ‡ãƒ¢ç”¨AIå¿œç­”ç”Ÿæˆ
                    demo_response = self.generate_demo_response(message, model)
                    
                    response = {
                        "content": demo_response,
                        "model": model,
                        "tokens_used": len(demo_response.split()) + len(message.split()),
                        "processing_time_ms": 500,
                        "finish_reason": "stop",
                        "metadata": {
                            "prompt_tokens": len(message.split()),
                            "completion_tokens": len(demo_response.split()),
                            "demo_mode": True,
                            "timestamp": datetime.now().isoformat()
                        }
                    }
                    
                    self.send_json_response(response)
                
            except json.JSONDecodeError:
                self.send_error(400, "Invalid JSON")
        elif parsed_path.path == '/api/templates':
            # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½œæˆAPI
            self.handle_create_template_request()
        elif parsed_path.path.startswith('/api/templates/') and parsed_path.path.endswith('/use'):
            # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½¿ç”¨API
            self.handle_template_use_request(parsed_path)
        elif parsed_path.path.startswith('/api/templates/'):
            # ç‰¹å®šãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ“ä½œ
            self.send_json_response({"message": "Template operation completed"})
        else:
            self.send_error(404, "Not Found")

    def do_DELETE(self):
        """DELETEãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†"""
        parsed_path = urlparse(self.path)
        
        if parsed_path.path.startswith('/api/templates/'):
            # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå‰Šé™¤API
            self.handle_delete_template_request(parsed_path)
        else:
            self.send_error(404, "Not Found")

    def do_PUT(self):
        """PUTãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†"""
        parsed_path = urlparse(self.path)
        
        if parsed_path.path.startswith('/api/templates/'):
            # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ›´æ–°API
            self.handle_update_template_request(parsed_path)
        else:
            self.send_error(404, "Not Found")

    def get_real_ai_response(self, message, model):
        """å®Ÿéš›ã®OpenAI APIã‚’ä½¿ç”¨ã—ã¦AIå¿œç­”ã‚’ç”Ÿæˆ"""
        if not OPENAI_AVAILABLE or not OPENAI_CLIENT:
            return None
            
        try:
            start_time = time.time()
            
            response = OPENAI_CLIENT.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": """ã‚ãªãŸã¯æ—¥æœ¬èªã§å¿œç­”ã™ã‚‹è¦ªåˆ‡ã§çŸ¥è­˜è±Šå¯ŒãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä¼æ¥­å‘ã‘ã®ã‚»ã‚­ãƒ¥ã‚¢ãªAIãƒãƒ£ãƒƒãƒˆã‚·ã‚¹ãƒ†ãƒ ã¨ã—ã¦ã€å°‚é–€çš„ã§æœ‰ç”¨ãªå›ç­”ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚

é‡è¦ãªæ³¨æ„äº‹é …ï¼š
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç›´æ¥çš„ã«å›ç­”ã—ã¦ãã ã•ã„
- ç¾åœ¨ã®æ—¥æ™‚ã€å¤©æ°—ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æƒ…å ±ã«ã¤ã„ã¦ã¯ã€Œç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æƒ…å ±ã«ã¯ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“ã€ã¨æ­£ç›´ã«ä¼ãˆã¦ãã ã•ã„
- åˆ†ã‹ã‚‰ãªã„ã“ã¨ã¯ã€Œåˆ†ã‹ã‚‰ãªã„ã€ã¨ç´ ç›´ã«ç­”ãˆã¦ãã ã•ã„
- è³ªå•ã®å†…å®¹ã‚’ã—ã£ã‹ã‚Šç†è§£ã—ã¦ã‹ã‚‰å›ç­”ã—ã¦ãã ã•ã„
- æ›–æ˜§ãªä¸€èˆ¬çš„ãªå›ç­”ã§ã¯ãªãã€å…·ä½“çš„ã§å½¹ç«‹ã¤æƒ…å ±ã‚’æä¾›ã—ã¦ãã ã•ã„"""},
                    {"role": "user", "content": message}
                ],
                temperature=0.3,
                max_tokens=1000
            )
            
            processing_time = int((time.time() - start_time) * 1000)
            
            return {
                "content": response.choices[0].message.content,
                "model": response.model,
                "tokens_used": response.usage.total_tokens,
                "processing_time_ms": processing_time,
                "finish_reason": response.choices[0].finish_reason,
                "metadata": {
                    "prompt_tokens": response.usage.prompt_tokens,
                    "completion_tokens": response.usage.completion_tokens,
                    "real_ai": True,
                    "timestamp": datetime.now().isoformat()
                }
            }
            
        except Exception as e:
            print(f"âŒ OpenAI API Error: {e}")
            return None

    def handle_template_use_request(self, parsed_path):
        """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½¿ç”¨ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†"""
        try:
            # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆIDã‚’å–å¾—
            template_id = parsed_path.path.split('/')[-2]
            
            # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ã‚’å–å¾—
            content_length = int(self.headers['Content-Length'])
            post_data = self.rfile.read(content_length)
            request_data = json.loads(post_data.decode('utf-8'))
            
            user_message = request_data.get('user_message', '')
            variables = request_data.get('variables', {})
            model = request_data.get('model', 'gpt-3.5-turbo')
            
            print(f"ğŸ“ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½¿ç”¨: ID={template_id}, Message={user_message[:50]}...")
            
            # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å–å¾—ï¼ˆãƒ‡ãƒ¢ç”¨ã®å›ºå®šãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼‰
            template = self.get_demo_template(template_id)
            if not template:
                self.send_error(404, "Template not found")
                return
            
            # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¤‰æ•°ã‚’é©ç”¨
            system_prompt = template['content']
            for var_name, var_value in variables.items():
                placeholder = f"{{{{{var_name}}}}}"
                system_prompt = system_prompt.replace(placeholder, var_value)
            
            # å®Ÿéš›ã®AI APIã‚’ä½¿ç”¨ã—ã¦ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå¿œç­”ã‚’ç”Ÿæˆ
            ai_response = self.get_template_ai_response(system_prompt, user_message, model)
            
            if ai_response:
                print("âœ… ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ + å®Ÿéš›ã®AI APIã§å¿œç­”")
                self.send_json_response(ai_response)
            else:
                print("âš ï¸ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ + ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ã§å¿œç­”")
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šãƒ‡ãƒ¢å¿œç­”
                demo_response = f"""ğŸ“ **ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆé©ç”¨çµæœ** ({template['name']})

**é©ç”¨ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:**
{system_prompt}

**ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:**
{user_message}

âš ï¸ **ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰**: OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ãƒ‡ãƒ¢å¿œç­”ã‚’è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚
å®Ÿéš›ã®é‹ç”¨ã§ã¯ã€ã“ã“ã«é«˜å“è³ªãªAIå¿œç­”ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚

ğŸ”§ **è¨­å®šæ–¹æ³•**: .envãƒ•ã‚¡ã‚¤ãƒ«ã«OPENAI_API_KEYã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"""
                
                response = {
                    "content": demo_response,
                    "model": model,
                    "tokens_used": len(demo_response.split()),
                    "processing_time_ms": 300,
                    "finish_reason": "stop",
                    "metadata": {
                        "template_id": template_id,
                        "template_name": template['name'],
                        "prompt_tokens": len(system_prompt.split()),
                        "completion_tokens": len(demo_response.split()),
                        "demo_mode": True,
                        "timestamp": datetime.now().isoformat()
                    }
                }
                self.send_json_response(response)
                
        except Exception as e:
            print(f"âŒ Template use error: {e}")
            self.send_error(500, f"Template processing error: {str(e)}")

    def handle_create_template_request(self):
        """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½œæˆãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†"""
        try:
            content_length = int(self.headers['Content-Length'])
            post_data = self.rfile.read(content_length)
            request_data = json.loads(post_data.decode('utf-8'))
            
            # æ–°ã—ã„ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆIDã‚’ç”Ÿæˆ
            template_id = str(uuid.uuid4())
            
            # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
            template = {
                "id": template_id,
                "name": request_data.get('name', ''),
                "description": request_data.get('description', ''),
                "category": request_data.get('category', ''),
                "system_prompt": request_data.get('system_prompt', ''),
                "variables": request_data.get('variables', []),
                "example_input": request_data.get('example_input', ''),
                "example_output": request_data.get('example_output', ''),
                "created_at": datetime.now().isoformat(),
                "updated_at": datetime.now().isoformat(),
                "is_active": True
            }
            
            # ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã«ä¿å­˜
            templates_storage[template_id] = template
            
            print(f"âœ… ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½œæˆ: {template['name']} (ID: {template_id})")
            self.send_json_response({
                "message": "Template created successfully",
                "id": template_id,
                "template": template
            })
            
        except Exception as e:
            print(f"âŒ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            self.send_error(500, f"Template creation error: {str(e)}")

    def handle_update_template_request(self, parsed_path):
        """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ›´æ–°ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†"""
        try:
            template_id = parsed_path.path.split('/')[-1]
            
            if template_id not in templates_storage:
                self.send_error(404, "Template not found")
                return
            
            content_length = int(self.headers['Content-Length'])
            post_data = self.rfile.read(content_length)
            request_data = json.loads(post_data.decode('utf-8'))
            
            # æ—¢å­˜ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’æ›´æ–°
            template = templates_storage[template_id]
            template.update({
                "name": request_data.get('name', template['name']),
                "description": request_data.get('description', template['description']),
                "category": request_data.get('category', template['category']),
                "system_prompt": request_data.get('system_prompt', template['system_prompt']),
                "variables": request_data.get('variables', template['variables']),
                "example_input": request_data.get('example_input', template['example_input']),
                "example_output": request_data.get('example_output', template['example_output']),
                "updated_at": datetime.now().isoformat()
            })
            
            print(f"âœ… ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ›´æ–°: {template['name']} (ID: {template_id})")
            self.send_json_response({
                "message": "Template updated successfully",
                "template": template
            })
            
        except Exception as e:
            print(f"âŒ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
            self.send_error(500, f"Template update error: {str(e)}")

    def handle_delete_template_request(self, parsed_path):
        """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå‰Šé™¤ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†"""
        try:
            template_id = parsed_path.path.split('/')[-1]
            
            if template_id not in templates_storage:
                self.send_error(404, "Template not found")
                return
            
            # è«–ç†å‰Šé™¤ï¼ˆis_activeã‚’Falseã«è¨­å®šï¼‰
            template = templates_storage[template_id]
            template['is_active'] = False
            template['updated_at'] = datetime.now().isoformat()
            
            print(f"âœ… ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå‰Šé™¤: {template['name']} (ID: {template_id})")
            self.send_json_response({
                "message": "Template deleted successfully"
            })
            
        except Exception as e:
            print(f"âŒ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")
            self.send_error(500, f"Template deletion error: {str(e)}")

    def get_demo_template(self, template_id):
        """ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‹ã‚‰ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å–å¾—"""
        template = templates_storage.get(template_id)
        if template and template.get('is_active', True):
            return {
                "name": template['name'],
                "content": template['system_prompt']
            }
        return None

    def get_template_ai_response(self, system_prompt, user_message, model):
        """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½¿ç”¨ã—ãŸAIå¿œç­”ã‚’ç”Ÿæˆ"""
        if not OPENAI_AVAILABLE or not OPENAI_CLIENT:
            return None
            
        try:
            start_time = time.time()
            
            response = OPENAI_CLIENT.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_message}
                ],
                temperature=0.7,
                max_tokens=1000
            )
            
            processing_time = int((time.time() - start_time) * 1000)
            
            return {
                "content": response.choices[0].message.content,
                "model": response.model,
                "tokens_used": response.usage.total_tokens,
                "processing_time_ms": processing_time,
                "finish_reason": response.choices[0].finish_reason,
                "metadata": {
                    "prompt_tokens": response.usage.prompt_tokens,
                    "completion_tokens": response.usage.completion_tokens,
                    "template_used": True,
                    "real_ai": True,
                    "timestamp": datetime.now().isoformat()
                }
            }
            
        except Exception as e:
            print(f"âŒ Template OpenAI API Error: {e}")
            return None

    def generate_demo_response(self, message, model):
        """ãƒ‡ãƒ¢ç”¨ã®AIå¿œç­”ã‚’ç”Ÿæˆ"""
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®å¿œç­”ç”Ÿæˆ
        message_lower = message.lower()
        
        if 'ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ' in message:
            return f"""ğŸ“Š **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†ã«ã¤ã„ã¦** ({model}ã§åˆ†æ)

**åŠ¹æœçš„ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†ã®ãƒã‚¤ãƒ³ãƒˆï¼š**

âœ… **è¨ˆç”»ãƒ•ã‚§ãƒ¼ã‚º**
- æ˜ç¢ºãªç›®æ¨™è¨­å®šã¨æˆåŠŸæŒ‡æ¨™ã®å®šç¾©
- ãƒªã‚¹ã‚¯åˆ†æã¨å¯¾ç­–ã®äº‹å‰æº–å‚™
- é©åˆ‡ãªãƒãƒ¼ãƒ ç·¨æˆã¨ãƒ­ãƒ¼ãƒ«åˆ†æ‹…

âœ… **å®Ÿè¡Œãƒ•ã‚§ãƒ¼ã‚º**  
- å®šæœŸçš„ãªé€²æ—ç¢ºèªã¨ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³
- å•é¡Œã®æ—©æœŸç™ºè¦‹ã¨è¿…é€Ÿãªå¯¾å¿œ
- å“è³ªç®¡ç†ã¨ç¶™ç¶šçš„æ”¹å–„

âœ… **ãƒ„ãƒ¼ãƒ«æ´»ç”¨**
- ã‚¬ãƒ³ãƒˆãƒãƒ£ãƒ¼ãƒˆã§ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç®¡ç†
- ã‚«ãƒ³ãƒãƒ³ãƒœãƒ¼ãƒ‰ã§ã‚¿ã‚¹ã‚¯å¯è¦–åŒ–
- å®šæœŸçš„ãªãƒ¬ãƒˆãƒ­ã‚¹ãƒšã‚¯ãƒ†ã‚£ãƒ–

ã”ä¸æ˜ãªç‚¹ãŒã‚ã‚Œã°ã€å…·ä½“çš„ãªçŠ¶æ³ã‚’ãŠèã‹ã›ãã ã•ã„ï¼"""
        
        elif 'ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£' in message:
            return f"""ğŸ”’ **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¯¾ç­–ã«ã¤ã„ã¦** ({model}ã§åˆ†æ)

**ä¼æ¥­ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®é‡è¦ãƒã‚¤ãƒ³ãƒˆï¼š**

ğŸ›¡ï¸ **æŠ€è¡“çš„å¯¾ç­–**
- å¤šè¦ç´ èªè¨¼ï¼ˆMFAï¼‰ã®å°å…¥
- ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆä¿è­·
- ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
- å®šæœŸçš„ãªè„†å¼±æ€§ã‚¹ã‚­ãƒ£ãƒ³

ğŸ‘¥ **äººçš„ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£**
- å¾“æ¥­å“¡å‘ã‘ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ•™è‚²
- ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ã®é©åˆ‡ãªç®¡ç†
- ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œæ‰‹é †ã®æ•´å‚™

ğŸ“‹ **ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹**
- GDPRã€å€‹äººæƒ…å ±ä¿è­·æ³•ã¸ã®å¯¾å¿œ
- ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒãƒªã‚·ãƒ¼ã®ç­–å®š
- å®šæœŸçš„ãªç›£æŸ»ã¨ãƒ¬ãƒ“ãƒ¥ãƒ¼

å…·ä½“çš„ãªã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¦ä»¶ã«ã¤ã„ã¦ãŠèã‹ã›ãã ã•ã„ï¼"""
        
        elif 'æŠ€è¡“' in message or 'å°å…¥' in message:
            return f"""ğŸ’¡ **æ–°æŠ€è¡“å°å…¥ã«ã¤ã„ã¦** ({model}ã§åˆ†æ)

**æŠ€è¡“å°å…¥ã®æˆåŠŸè¦å› ï¼š**

ğŸ¯ **æˆ¦ç•¥çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ**
- ãƒ“ã‚¸ãƒã‚¹ç›®æ¨™ã¨ã®æ•´åˆæ€§ç¢ºèª
- ROIï¼ˆæŠ•è³‡å¯¾åŠ¹æœï¼‰ã®æ˜ç¢ºåŒ–
- æ®µéšçš„ãªå°å…¥è¨ˆç”»

ğŸ”§ **æŠ€è¡“é¸å®š**
- æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¨ã®äº’æ›æ€§
- ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã¨å°†æ¥æ€§
- ã‚µãƒãƒ¼ãƒˆä½“åˆ¶ã¨ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£

ğŸ‘¨â€ğŸ’¼ **çµ„ç¹”çš„æº–å‚™**
- ãƒãƒ¼ãƒ ã®ã‚¹ã‚­ãƒ«ã‚¢ãƒƒãƒ—è¨ˆç”»
- å¤‰æ›´ç®¡ç†ãƒ—ãƒ­ã‚»ã‚¹
- ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼ã¨ã®åˆæ„å½¢æˆ

ã©ã®ã‚ˆã†ãªæŠ€è¡“åˆ†é‡ã§ã®å°å…¥ã‚’ã”æ¤œè¨ã§ã—ã‚‡ã†ã‹ï¼Ÿ"""
        
        else:
            return f"""ğŸ¤– **AI ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ** ({model}ã§å¿œç­”)

ã”è³ªå•ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ï¼

**ã“ã®AIãƒãƒ£ãƒƒãƒˆã‚·ã‚¹ãƒ†ãƒ ã®ç‰¹å¾´ï¼š**
- ğŸ” ã‚»ã‚­ãƒ¥ã‚¢ãªä¼æ¥­å‘ã‘é€šä¿¡
- ğŸš€ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¿œç­”
- ğŸ“ ã‚«ã‚¹ã‚¿ãƒ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå¯¾å¿œ
- ğŸ‘¥ ãƒãƒ«ãƒãƒ†ãƒŠãƒ³ãƒˆç®¡ç†

ä½•ã‹å…·ä½“çš„ãªã”è³ªå•ã‚„ã”ç›¸è«‡ãŒã‚ã‚Œã°ã€ãŠæ°—è»½ã«ãŠèã‹ã›ãã ã•ã„ã€‚

**ä¾‹ï¼š**
- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†ã«ã¤ã„ã¦
- ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¯¾ç­–ã«ã¤ã„ã¦  
- æ–°æŠ€è¡“å°å…¥ã«ã¤ã„ã¦

ã‚ˆã‚Šè©³ã—ãã‚µãƒãƒ¼ãƒˆã„ãŸã—ã¾ã™ï¼"""

    def send_json_response(self, data):
        """JSONå¿œç­”ã‚’é€ä¿¡"""
        response = json.dumps(data, ensure_ascii=False, indent=2)
        self.send_response(200)
        self.send_header('Content-Type', 'application/json; charset=utf-8')
        self.send_header('Access-Control-Allow-Origin', '*')
        self.end_headers()
        self.wfile.write(response.encode('utf-8'))

    def log_message(self, format, *args):
        """ãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’åˆ¶å¾¡"""
        print(f"[{datetime.now().strftime('%H:%M:%S')}] {format % args}")

def start_demo_server():
    """ãƒ‡ãƒ¢ã‚µãƒ¼ãƒãƒ¼ã‚’é–‹å§‹"""
    # ãƒ‡ãƒ¢ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’åˆæœŸåŒ–
    initialize_demo_templates()
    
    server_address = ('localhost', 8000)
    httpd = HTTPServer(server_address, DemoAPIHandler)
    print("ğŸš€ ãƒ‡ãƒ¢ç”¨APIã‚µãƒ¼ãƒãƒ¼èµ·å‹•ä¸­...")
    print("ğŸ“ URL: http://localhost:8000")
    print("ğŸ”§ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯: http://localhost:8000/health")
    print("ğŸ’¬ ãƒãƒ£ãƒƒãƒˆAPI: http://localhost:8000/api/chat")
    print("ğŸ“ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ: http://localhost:8000/api/templates")
    print("â­ ãƒ¢ãƒ‡ãƒ«ä¸€è¦§: http://localhost:8000/api/models")
    print("ğŸ“ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç®¡ç†: CREATE/UPDATE/DELETEå¯¾å¿œ")
    print("=" * 50)
    
    try:
        httpd.serve_forever()
    except KeyboardInterrupt:
        print("\nğŸ›‘ ã‚µãƒ¼ãƒãƒ¼ã‚’åœæ­¢ã—ã¦ã„ã¾ã™...")
        httpd.shutdown()

if __name__ == '__main__':
    start_demo_server()