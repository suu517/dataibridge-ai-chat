#!/usr/bin/env python3
"""
ç°¡æ˜“APIã‚µãƒ¼ãƒãƒ¼ - OpenAI APIãƒ†ã‚¹ãƒˆç”¨
"""

import os
import asyncio
from fastapi import FastAPI, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import openai
from openai import AsyncOpenAI
import json
import uuid
from datetime import datetime

# èªè¨¼ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from app.api.auth import router as auth_router
from app.core.middleware import TenantMiddleware, require_auth, get_current_user
from app.models.auth import User

# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã¿
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
if not OPENAI_API_KEY:
    print("WARNING: OPENAI_API_KEY not found in environment variables")

# FastAPIã‚¢ãƒ—ãƒªä½œæˆ
app = FastAPI(title="Secure AI Chat API", version="1.0.0")

# ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢è¨­å®š
app.add_middleware(TenantMiddleware)

# CORSè¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # é–‹ç™ºç”¨ï¼šæœ¬ç•ªã§ã¯åˆ¶é™ã™ã‚‹
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# èªè¨¼ãƒ«ãƒ¼ã‚¿ãƒ¼è¿½åŠ 
app.include_router(auth_router)

# ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ»ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«
class ChatMessage(BaseModel):
    role: str
    content: str

class ChatRequest(BaseModel):
    messages: List[ChatMessage]
    model: str = "gpt-3.5-turbo"
    temperature: float = 0.7
    max_tokens: int = 500

class ChatResponse(BaseModel):
    content: str
    model: str
    tokens_used: int
    processing_time_ms: int
    finish_reason: str
    metadata: dict

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆé–¢é€£ã®ãƒ¢ãƒ‡ãƒ«
class PromptTemplate(BaseModel):
    id: str
    name: str
    description: Optional[str] = None
    category: str
    system_prompt: str
    variables: List[Dict[str, Any]] = []
    example_input: Optional[str] = None
    example_output: Optional[str] = None
    created_at: str
    updated_at: str
    is_active: bool = True

class CreateTemplateRequest(BaseModel):
    name: str
    description: Optional[str] = None
    category: str
    system_prompt: str
    variables: List[Dict[str, Any]] = []
    example_input: Optional[str] = None
    example_output: Optional[str] = None

class UpdateTemplateRequest(BaseModel):
    name: Optional[str] = None
    description: Optional[str] = None
    category: Optional[str] = None
    system_prompt: Optional[str] = None
    variables: Optional[List[Dict[str, Any]]] = None
    example_input: Optional[str] = None
    example_output: Optional[str] = None
    is_active: Optional[bool] = None

class UseTemplateRequest(BaseModel):
    variables: Dict[str, str] = {}
    user_message: str
    model: str = "gpt-3.5-turbo"

# ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªãƒ¼ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰
templates_storage: Dict[str, PromptTemplate] = {}

# ãƒ‡ãƒ¢ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½œæˆ
def create_demo_templates():
    demo_templates = [
        PromptTemplate(
            id="business_email",
            name="ğŸ“§ ãƒ“ã‚¸ãƒã‚¹ãƒ¡ãƒ¼ãƒ«ä½œæˆ",
            description="æƒ…å ±ã‚’å…¥åŠ›ã™ã‚‹ã ã‘ã§ã€ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªãƒ“ã‚¸ãƒã‚¹ãƒ¡ãƒ¼ãƒ«ã‚’è‡ªå‹•ç”Ÿæˆ",
            category="ãƒ“ã‚¸ãƒã‚¹",
            system_prompt="""ã‚ãªãŸã¯30å¹´ã®çµŒé¨“ã‚’æŒã¤ä¸€æµã®ãƒ“ã‚¸ãƒã‚¹ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³å°‚é–€å®¶ã§ã™ã€‚
ä»¥ä¸‹ã®æŒ‡é‡ã«å¾“ã£ã¦ã€æœ€é«˜å“è³ªã®ãƒ“ã‚¸ãƒã‚¹ãƒ¡ãƒ¼ãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š

ã€ãƒ¡ãƒ¼ãƒ«æ§‹æˆã®åŸºæœ¬åŸå‰‡ã€‘
1. ä»¶å: å†…å®¹ãŒä¸€ç›®ã§åˆ†ã‹ã‚‹å…·ä½“çš„ã§ç°¡æ½”ãªã‚‚ã®
2. å®›å: æ•¬èªã‚’é©åˆ‡ã«ä½¿ç”¨ã—ã€ç›¸æ‰‹ã®ç«‹å ´ã‚’è€ƒæ…®
3. æŒ¨æ‹¶: é–¢ä¿‚æ€§ã«å¿œã˜ãŸé©åˆ‡ãªæŒ¨æ‹¶æ–‡
4. æœ¬æ–‡: ç›®çš„ã‚’æ˜ç¢ºã«ä¼ãˆã€å…·ä½“çš„ã§è¡Œå‹•ã—ã‚„ã™ã„å†…å®¹
5. ç· ã‚: æ„Ÿè¬ã®æ°—æŒã¡ã¨ä»Šå¾Œã®é–¢ä¿‚ç¶™ç¶šã¸ã®é…æ…®
6. ç½²å: å¿…è¦ã«å¿œã˜ã¦é€£çµ¡å…ˆæƒ…å ±ã‚’å«ã‚€

ã€ãƒˆãƒ¼ãƒ³åˆ¥ã®èª¿æ•´ã€‘
- ãƒ•ã‚©ãƒ¼ãƒãƒ«: æ•¬èªã‚’å¾¹åº•ã—ã€æ ¼å¼é«˜ã„è¡¨ç¾ã‚’ä½¿ç”¨
- ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«: è¦ªã—ã¿ã‚„ã™ã•ã‚’ä¿ã¡ãªãŒã‚‰ç¤¼å„€ã¯ç¶­æŒ
- å‹å¥½çš„: æ¸©ã‹ã¿ã®ã‚ã‚‹è¡¨ç¾ã§é–¢ä¿‚æ€§ã‚’é‡è¦–

ã€å¿…é ˆè¦ç´ ã€‘
- ç›¸æ‰‹ï¼ˆ{recipient}ï¼‰ã¸ã®é…æ…®ã‚’æœ€å„ªå…ˆ
- ç›®çš„ï¼ˆ{purpose}ï¼‰ã‚’æ˜ç¢ºã‹ã¤å…·ä½“çš„ã«ä¼é”
- é¸æŠã•ã‚ŒãŸãƒˆãƒ¼ãƒ³ï¼ˆ{tone}ï¼‰ã«å®Œå…¨ã«åˆè‡´
- æ—¥æœ¬ã®ãƒ“ã‚¸ãƒã‚¹æ–‡åŒ–ã«é©åˆ
- èª­ã¿æ‰‹ãŒè¡Œå‹•ã—ã‚„ã™ã„å…·ä½“çš„ãªææ¡ˆ

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚ã‚’åˆ†æã—ã€ä¸Šè¨˜ã®å°‚é–€çŸ¥è­˜ã‚’æ´»ç”¨ã—ã¦å®Œç’§ãªãƒ“ã‚¸ãƒã‚¹ãƒ¡ãƒ¼ãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚""",
            variables=[
                {"name": "recipient", "type": "string", "description": "ãƒ¡ãƒ¼ãƒ«ã®é€ä¿¡å…ˆï¼ˆä¾‹: ç”°ä¸­éƒ¨é•·ã€å±±ç”°æ§˜ï¼‰", "required": True},
                {"name": "purpose", "type": "string", "description": "ãƒ¡ãƒ¼ãƒ«ã®ç›®çš„ï¼ˆä¾‹: ä¼šè­°ã®æ—¥ç¨‹èª¿æ•´ã€è³‡æ–™ã®é€ä»˜ï¼‰", "required": True},
                {"name": "tone", "type": "select", "options": ["ãƒ•ã‚©ãƒ¼ãƒãƒ«", "ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«", "å‹å¥½çš„"], "default": "ãƒ•ã‚©ãƒ¼ãƒãƒ«", "description": "ãƒ¡ãƒ¼ãƒ«ã®ãƒˆãƒ¼ãƒ³"}
            ],
            example_input="æ¥é€±ã®ä¼ç”»ä¼šè­°ã®æ™‚é–“ã‚’å¤‰æ›´ã—ãŸã„ã®ã§ãŠçŸ¥ã‚‰ã›ã—ã¾ã™",
            example_output="ä»¶å: ä¼ç”»ä¼šè­°ã®æ—¥ç¨‹å¤‰æ›´ã®ãŠçŸ¥ã‚‰ã›\n\nç”°ä¸­éƒ¨é•·\n\nã„ã¤ã‚‚ãŠä¸–è©±ã«ãªã£ã¦ãŠã‚Šã¾ã™...",
            created_at=datetime.now().isoformat(),
            updated_at=datetime.now().isoformat(),
            is_active=True
        ),
        PromptTemplate(
            id="code_review",
            name="ğŸ” AIã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼",
            description="ã‚³ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã™ã‚‹ã ã‘ã§ã€ãƒ—ãƒ­ã®é–‹ç™ºè€…ãƒ¬ãƒ™ãƒ«ã®è©³ç´°ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å®Ÿè¡Œ",
            category="é–‹ç™º",
            system_prompt="""ã‚ãªãŸã¯20å¹´ä»¥ä¸Šã®çµŒé¨“ã‚’æŒã¤ã‚·ãƒ‹ã‚¢ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢å…¼ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ãƒšã‚·ãƒ£ãƒªã‚¹ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®å°‚é–€çš„ãªè¦³ç‚¹ã‹ã‚‰ã€æä¾›ã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã‚’åŒ…æ‹¬çš„ã«åˆ†æã—ã¦ãã ã•ã„ï¼š

ã€åˆ†æè¦³ç‚¹ã€‘
ğŸ”’ **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£**: è„†å¼±æ€§ã€ã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³æ”»æ’ƒã€èªè¨¼ãƒ»èªå¯ã®å•é¡Œ
âš¡ **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹**: è¨ˆç®—é‡ã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªæœ€é©åŒ–
ğŸ“– **å¯èª­æ€§**: ã‚³ãƒ¼ãƒ‰æ§‹é€ ã€å‘½åè¦å‰‡ã€ã‚³ãƒ¡ãƒ³ãƒˆã€ä¿å®ˆæ€§
ğŸ—ï¸ **ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**: è¨­è¨ˆãƒ‘ã‚¿ãƒ¼ãƒ³ã€SOLIDåŸå‰‡ã€åˆ†é›¢åº¦
ğŸ§ª **ãƒ†ã‚¹ã‚¿ãƒ“ãƒªãƒ†ã‚£**: å˜ä½“ãƒ†ã‚¹ãƒˆå®¹æ˜“æ€§ã€ä¾å­˜é–¢ä¿‚æ³¨å…¥

ã€ãƒ¬ãƒ“ãƒ¥ãƒ¼å½¢å¼ã€‘
1. **æ¦‚è¦è©•ä¾¡** (1-10ç‚¹)
2. **è‰¯ã„ç‚¹** (å…·ä½“çš„ãªç®‡æ‰€ã‚’å¼•ç”¨)
3. **æ”¹å–„ç‚¹** (å„ªå…ˆåº¦ä»˜ãã€å…·ä½“çš„ãªä¿®æ­£æ¡ˆ)
4. **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è­¦å‘Š** (è©²å½“ã™ã‚‹å ´åˆ)
5. **ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ææ¡ˆ** (æ”¹è‰¯ç‰ˆã‚³ãƒ¼ãƒ‰ä¾‹)

ã€é‡ç‚¹åˆ†æé …ç›®ã€‘
- {language}è¨€èªã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹æº–æ‹ 
- {focus}ã®è¦³ç‚¹ã‚’ç‰¹ã«é‡è¦–
- æ¥­ç•Œæ¨™æº–è¦æ ¼ã¸ã®é©åˆæ€§
- å°†æ¥ã®ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹æ€§

ãƒ—ãƒ­ã®é–‹ç™ºãƒãƒ¼ãƒ ã§è¡Œã‚ã‚Œã‚‹å®Ÿéš›ã®ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ã¨åŒç­‰ã®å“è³ªã§ã€å»ºè¨­çš„ã§å®Ÿç”¨çš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚""",
            variables=[
                {"name": "language", "type": "string", "description": "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªï¼ˆä¾‹: Python, JavaScript, Javaï¼‰", "required": True},
                {"name": "focus", "type": "select", "options": ["ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£", "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹", "å¯èª­æ€§", "å…¨èˆ¬"], "default": "å…¨èˆ¬", "description": "é‡ç‚¹çš„ã«ãƒã‚§ãƒƒã‚¯ã—ãŸã„é …ç›®"}
            ],
            example_input="ã“ã®Pythoné–¢æ•°ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ãã ã•ã„",
            example_output="## ğŸ” ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœ\n\n**ç·åˆè©•ä¾¡: 7/10**\n\n### âœ… è‰¯ã„ç‚¹\n- é–¢æ•°åãŒå‡¦ç†å†…å®¹ã‚’é©åˆ‡ã«è¡¨ç¾...",
            created_at=datetime.now().isoformat(),
            updated_at=datetime.now().isoformat(),
            is_active=True
        ),
        PromptTemplate(
            id="creative_writing",
            name="âœï¸ ã‚¹ãƒˆãƒ¼ãƒªãƒ¼å‰µä½œæ”¯æ´",
            description="ã‚ã‚‰ã™ã˜ã‚’å…¥åŠ›ã™ã‚‹ã ã‘ã§ã€é­…åŠ›çš„ãªç‰©èªã®è©³ç´°ãƒ—ãƒ­ãƒƒãƒˆã‚’è‡ªå‹•ç”Ÿæˆ",
            category="ã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–",
            system_prompt="""ã‚ãªãŸã¯æ•°ã€…ã®ãƒ™ã‚¹ãƒˆã‚»ãƒ©ãƒ¼ä½œå“ã‚’æ‰‹æ›ã‘ãŸçµŒé¨“è±Šå¯Œãªå°èª¬å®¶å…¼ç·¨é›†è€…ã§ã™ã€‚
{genre}ã‚¸ãƒ£ãƒ³ãƒ«ã®å°‚é–€çŸ¥è­˜ã‚’æ´»ç”¨ã—ã€ä»¥ä¸‹ã®è¦ç´ ã‚’å«ã‚€é­…åŠ›çš„ãªç‰©èªã‚’æ§‹ç¯‰ã—ã¦ãã ã•ã„ï¼š

ã€å‰µä½œæŒ‡é‡ã€‘
ğŸ“– **ç‰©èªæ§‹é€ **: èµ·æ‰¿è»¢çµã‚’æ˜ç¢ºã«è¨­å®šã—ã€èª­è€…ã‚’å¼•ãè¾¼ã‚€å±•é–‹
ğŸ‘¥ **ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼**: ç«‹ä½“çš„ã§å…±æ„Ÿã§ãã‚‹ç™»å ´äººç‰©ã®è¨­å®š
ğŸŒ **ä¸–ç•Œè¦³**: {genre}ã‚¸ãƒ£ãƒ³ãƒ«ã«ãµã•ã‚ã—ã„è©³ç´°ãªè¨­å®š
âš¡ **ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆ**: ä¸»äººå…¬ãŒç›´é¢ã™ã‚‹å†…çš„ãƒ»å¤–çš„ãªè‘›è—¤
ğŸ’« **ãƒ†ãƒ¼ãƒ**: {theme}ã‚’ç‰©èªã«è‡ªç„¶ã«ç¹”ã‚Šè¾¼ã‚€

ã€{genre}ã‚¸ãƒ£ãƒ³ãƒ«ã®ç‰¹å¾´ã‚’æ´»ç”¨ã€‘
- ã‚¸ãƒ£ãƒ³ãƒ«å›ºæœ‰ã®é­…åŠ›çš„ãªè¦ç´ ã‚’ç››ã‚Šè¾¼ã‚€
- èª­è€…ã®æœŸå¾…ã«å¿œãˆã¤ã¤ã€æ„å¤–æ€§ã‚‚æä¾›
- ã‚¸ãƒ£ãƒ³ãƒ«ã®å®šç•ªã‚’ç†è§£ã—ãŸä¸Šã§ã®ç‹¬å‰µæ€§

ã€{length}ã«é©ã—ãŸæ§‹æˆã€‘
- é©åˆ‡ãªæƒ…å ±å¯†åº¦ã¨å±•é–‹é€Ÿåº¦
- èª­è€…ãŒæœ€å¾Œã¾ã§èª­ã¿é€šã›ã‚‹ãƒšãƒ¼ã‚¹é…åˆ†
- ã‚¯ãƒ©ã‚¤ãƒãƒƒã‚¯ã‚¹ã¸ã®åŠ¹æœçš„ãªç››ã‚Šä¸Šã’

ã€ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆå½¢å¼ã€‘
1. **ã‚ã‚‰ã™ã˜** (é­…åŠ›çš„ãªè¦ç´„)
2. **ä¸»è¦ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼** (3-5äººã€è©³ç´°è¨­å®š)
3. **ãƒ—ãƒ­ãƒƒãƒˆ** (ç« æ§‹æˆã¨ä¸»è¦äº‹ä»¶)
4. **ä¸–ç•Œè¦³ãƒ»è¨­å®š** (èˆå°èƒŒæ™¯)
5. **ãƒ†ãƒ¼ãƒã¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸**
6. **èª­è€…ã¸ã®ã‚¢ãƒ”ãƒ¼ãƒ«ãƒã‚¤ãƒ³ãƒˆ**

èª­è€…ãŒã€Œã“ã®ç‰©èªã‚’èª­ã¿ãŸã„ï¼ã€ã¨æ€ãˆã‚‹ã€å‡ºç‰ˆãƒ¬ãƒ™ãƒ«ã®ä¼ç”»æ›¸ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚""",
            variables=[
                {"name": "genre", "type": "select", "options": ["ãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼", "SF", "ãƒŸã‚¹ãƒ†ãƒªãƒ¼", "æ‹æ„›", "ãƒ›ãƒ©ãƒ¼", "æ­´å²å°èª¬", "å†’é™º"], "required": True, "description": "ç‰©èªã®ã‚¸ãƒ£ãƒ³ãƒ«"},
                {"name": "length", "type": "select", "options": ["çŸ­ç·¨", "ä¸­ç·¨", "é•·ç·¨"], "default": "çŸ­ç·¨", "description": "ä½œå“ã®é•·ã•"},
                {"name": "theme", "type": "string", "description": "ç‰©èªã«è¾¼ã‚ãŸã„ãƒ†ãƒ¼ãƒï¼ˆä¾‹: å‹æƒ…ã€æˆé•·ã€é‹å‘½ï¼‰", "required": True}
            ],
            example_input="è¿‘æœªæ¥ã®å®‡å®™ã‚¹ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã§èµ·ã“ã‚‹è¬ã®äº‹ä»¶ã«ã¤ã„ã¦",
            example_output="# ğŸ“š ç‰©èªä¼ç”»æ›¸\n\n## ã‚ã‚‰ã™ã˜\nè¥¿æš¦2087å¹´ã€ç«æ˜Ÿè»Œé“ä¸Šã®å®‡å®™ã‚¹ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€Œã‚¢ãƒ«ãƒ†ãƒŸã‚¹7ã€ã§...",
            created_at=datetime.now().isoformat(),
            updated_at=datetime.now().isoformat(),
            is_active=True
        ),
        PromptTemplate(
            id="meeting_minutes",
            name="ğŸ“ è­°äº‹éŒ²ä½œæˆ",
            description="ä¼šè­°å†…å®¹ã‚’å…¥åŠ›ã™ã‚‹ã ã‘ã§ã€æ•´ç†ã•ã‚ŒãŸè¦‹ã‚„ã™ã„è­°äº‹éŒ²ã‚’è‡ªå‹•ä½œæˆ",
            category="ãƒ“ã‚¸ãƒã‚¹",
            system_prompt="""ã‚ãªãŸã¯ä¼æ¥­ç§˜æ›¸ã‚„ä¼šè­°é‹å–¶ã®å°‚é–€å®¶ã¨ã—ã¦ã€åŠ¹æœçš„ãªè­°äº‹éŒ²ã‚’ä½œæˆã—ã¾ã™ã€‚
ä»¥ä¸‹ã®æ§‹é€ åŒ–ã•ã‚ŒãŸå½¢å¼ã§ã€ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªè­°äº‹éŒ²ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š

ã€è­°äº‹éŒ²ã®åŸºæœ¬æ§‹æˆã€‘
ğŸ“… **ä¼šè­°æƒ…å ±**: æ—¥æ™‚ã€å‚åŠ è€…ã€ä¼šè­°å
ğŸ“‹ **ã‚¢ã‚¸ã‚§ãƒ³ãƒ€**: è­°é¡Œã®æ•´ç†ã¨åˆ†é¡
ğŸ’¬ **è¨è­°å†…å®¹**: ä¸»è¦ãªæ„è¦‹ã‚„ææ¡ˆã®è¦ç´„
âœ… **æ±ºå®šäº‹é …**: åˆæ„ã«è‡³ã£ãŸå†…å®¹ã‚’æ˜ç¢ºåŒ–
ğŸ“ **ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ **: æ‹…å½“è€…ã¨æœŸé™ä»˜ãã®ã‚¿ã‚¹ã‚¯
ğŸ“Œ **æ¬¡å›äºˆå®š**: ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—äº‹é …

ã€å“è³ªåŸºæº–ã€‘
- å‚åŠ ã—ã¦ã„ãªã„äººãŒèª­ã‚“ã§ã‚‚å†…å®¹ãŒç†è§£ã§ãã‚‹
- æ±ºå®šäº‹é …ã¨æ¤œè¨äº‹é …ã‚’æ˜ç¢ºã«åŒºåˆ¥
- ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ ã¯å…·ä½“çš„ã§å®Ÿè¡Œå¯èƒ½
- {meeting_type}ä¼šè­°ã«ãµã•ã‚ã—ã„è©³ç´°åº¦
- é‡è¦åº¦ã«å¿œã˜ãŸæƒ…å ±ã®æ§‹é€ åŒ–

ã€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆèª¿æ•´ã€‘
- {format}å½¢å¼ã§ã®å‡ºåŠ›
- èª­ã¿ã‚„ã™ã„ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã¨è¦‹å‡ºã—
- å¿…è¦ã«å¿œã˜ã¦å›³è¡¨ã‚„ç®‡æ¡æ›¸ãã‚’æ´»ç”¨

ä¼šè­°å‚åŠ è€…å…¨å“¡ãŒåˆæ„ã§ãã‚‹ã€æ­£ç¢ºã§æœ‰ç”¨ãªè­°äº‹éŒ²ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚""",
            variables=[
                {"name": "meeting_type", "type": "select", "options": ["å®šä¾‹ä¼šè­°", "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¼šè­°", "å½¹å“¡ä¼šè­°", "ä¼ç”»ä¼šè­°", "é€²æ—ä¼šè­°"], "default": "å®šä¾‹ä¼šè­°", "description": "ä¼šè­°ã®ç¨®é¡"},
                {"name": "format", "type": "select", "options": ["æ¨™æº–", "è©³ç´°", "ç°¡æ½”"], "default": "æ¨™æº–", "description": "è­°äº‹éŒ²ã®è©³ç´°åº¦"}
            ],
            example_input="ä»Šæ—¥ã®å–¶æ¥­éƒ¨ã®é€±æ¬¡ä¼šè­°ã«ã¤ã„ã¦æ•´ç†ã—ã¦ãã ã•ã„",
            example_output="# ğŸ“ å–¶æ¥­éƒ¨é€±æ¬¡ä¼šè­° è­°äº‹éŒ²\n\n**æ—¥æ™‚**: 2024å¹´...\n**å‚åŠ è€…**: ...\n\n## ğŸ“‹ è¨è­°å†…å®¹\n...",
            created_at=datetime.now().isoformat(),
            updated_at=datetime.now().isoformat(),
            is_active=True
        )
    ]
    
    for template in demo_templates:
        templates_storage[template.id] = template

# åˆæœŸåŒ–æ™‚ã«ãƒ‡ãƒ¢ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆ
create_demo_templates()

# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
@app.get("/")
async def root():
    return {
        "message": "ğŸ” Secure AI Chat API",
        "version": "1.0.0",
        "status": "ready",
        "features": ["AI Chat", "Prompt Templates"]
    }

@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "service": "Secure AI Chat",
        "version": "1.0.0"
    }

# AI ãƒãƒ£ãƒƒãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.post("/api/v1/ai/chat", response_model=ChatResponse)
async def chat_completion(
    request: ChatRequest, 
    current_user: Optional[User] = Depends(get_current_user)
):
    """AI ãƒãƒ£ãƒƒãƒˆè£œå®Œ"""
    
    if not OPENAI_API_KEY:
        raise HTTPException(
            status_code=500,
            detail="OpenAI API key not configured"
        )
    
    try:
        # OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä½œæˆ
        client = AsyncOpenAI(api_key=OPENAI_API_KEY)
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å¤‰æ›
        messages = [{"role": msg.role, "content": msg.content} for msg in request.messages]
        
        import time
        start_time = time.time()
        
        # APIå‘¼ã³å‡ºã—
        response = await client.chat.completions.create(
            model=request.model,
            messages=messages,
            temperature=request.temperature,
            max_tokens=request.max_tokens
        )
        
        processing_time = int((time.time() - start_time) * 1000)
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ä½œæˆ
        return ChatResponse(
            content=response.choices[0].message.content,
            model=response.model,
            tokens_used=response.usage.total_tokens if response.usage else 0,
            processing_time_ms=processing_time,
            finish_reason=response.choices[0].finish_reason,
            metadata={
                "prompt_tokens": response.usage.prompt_tokens if response.usage else 0,
                "completion_tokens": response.usage.completion_tokens if response.usage else 0,
            }
        )
        
    except openai.AuthenticationError:
        raise HTTPException(
            status_code=401,
            detail="Invalid OpenAI API key"
        )
    except openai.RateLimitError:
        raise HTTPException(
            status_code=429,
            detail="OpenAI API rate limit exceeded. Please check your billing and quota settings."
        )
    except openai.APIError as e:
        raise HTTPException(
            status_code=500,
            detail=f"OpenAI API error: {str(e)}"
        )
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Internal server error: {str(e)}"
        )

# ãƒ¢ãƒ‡ãƒ«ä¸€è¦§å–å¾—
@app.get("/api/v1/ai/models")
async def get_models():
    """åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—"""
    
    if not OPENAI_API_KEY:
        raise HTTPException(
            status_code=500,
            detail="OpenAI API key not configured"
        )
    
    try:
        client = AsyncOpenAI(api_key=OPENAI_API_KEY)
        models = await client.models.list()
        
        # GPTãƒ¢ãƒ‡ãƒ«ã®ã¿ãƒ•ã‚£ãƒ«ã‚¿
        gpt_models = []
        for model in models.data:
            if any(keyword in model.id for keyword in ['gpt-3.5', 'gpt-4']):
                gpt_models.append({
                    "id": model.id,
                    "name": model.id,
                    "description": f"OpenAI {model.id}",
                    "max_tokens": 4096 if "gpt-3.5" in model.id else 8192,
                    "cost_per_1k_tokens": 0.002 if "gpt-3.5" in model.id else 0.03
                })
        
        return gpt_models
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Failed to fetch models: {str(e)}"
        )

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç®¡ç†API

@app.get("/api/v1/templates", response_model=List[PromptTemplate])
async def get_templates(category: Optional[str] = None):
    """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä¸€è¦§ã‚’å–å¾—"""
    templates = list(templates_storage.values())
    
    if category:
        templates = [t for t in templates if t.category.lower() == category.lower()]
    
    # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®ã¿è¿”ã™
    active_templates = [t for t in templates if t.is_active]
    return sorted(active_templates, key=lambda x: x.updated_at, reverse=True)

@app.get("/api/v1/templates/categories")
async def get_categories():
    """åˆ©ç”¨å¯èƒ½ãªãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚«ãƒ†ã‚´ãƒªä¸€è¦§ã‚’å–å¾—"""
    categories = list(set(t.category for t in templates_storage.values() if t.is_active))
    return sorted(categories)

@app.get("/api/v1/templates/{template_id}", response_model=PromptTemplate)
async def get_template(template_id: str):
    """æŒ‡å®šã•ã‚ŒãŸãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å–å¾—"""
    if template_id not in templates_storage:
        raise HTTPException(status_code=404, detail="Template not found")
    
    template = templates_storage[template_id]
    if not template.is_active:
        raise HTTPException(status_code=404, detail="Template not active")
    
    return template

@app.post("/api/v1/templates", response_model=PromptTemplate)
async def create_template(template_data: CreateTemplateRequest):
    """æ–°ã—ã„ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆ"""
    template_id = str(uuid.uuid4())
    now = datetime.now().isoformat()
    
    template = PromptTemplate(
        id=template_id,
        name=template_data.name,
        description=template_data.description,
        category=template_data.category,
        system_prompt=template_data.system_prompt,
        variables=template_data.variables,
        example_input=template_data.example_input,
        example_output=template_data.example_output,
        created_at=now,
        updated_at=now,
        is_active=True
    )
    
    templates_storage[template_id] = template
    return template

@app.put("/api/v1/templates/{template_id}", response_model=PromptTemplate)
async def update_template(template_id: str, template_data: UpdateTemplateRequest):
    """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’æ›´æ–°"""
    if template_id not in templates_storage:
        raise HTTPException(status_code=404, detail="Template not found")
    
    template = templates_storage[template_id]
    
    # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æ›´æ–°
    if template_data.name is not None:
        template.name = template_data.name
    if template_data.description is not None:
        template.description = template_data.description
    if template_data.category is not None:
        template.category = template_data.category
    if template_data.system_prompt is not None:
        template.system_prompt = template_data.system_prompt
    if template_data.variables is not None:
        template.variables = template_data.variables
    if template_data.example_input is not None:
        template.example_input = template_data.example_input
    if template_data.example_output is not None:
        template.example_output = template_data.example_output
    if template_data.is_active is not None:
        template.is_active = template_data.is_active
    
    template.updated_at = datetime.now().isoformat()
    templates_storage[template_id] = template
    return template

@app.delete("/api/v1/templates/{template_id}")
async def delete_template(template_id: str):
    """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å‰Šé™¤ï¼ˆéæ´»æ€§åŒ–ï¼‰"""
    if template_id not in templates_storage:
        raise HTTPException(status_code=404, detail="Template not found")
    
    # å®Œå…¨å‰Šé™¤ã§ã¯ãªãéæ´»æ€§åŒ–
    template = templates_storage[template_id]
    template.is_active = False
    template.updated_at = datetime.now().isoformat()
    
    return {"message": "Template deactivated successfully"}

@app.post("/api/v1/templates/{template_id}/use", response_model=ChatResponse)
async def use_template(template_id: str, request: UseTemplateRequest):
    """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½¿ç”¨ã—ã¦AIãƒãƒ£ãƒƒãƒˆ"""
    if template_id not in templates_storage:
        raise HTTPException(status_code=404, detail="Template not found")
    
    template = templates_storage[template_id]
    if not template.is_active:
        raise HTTPException(status_code=404, detail="Template not active")
    
    if not OPENAI_API_KEY:
        raise HTTPException(status_code=500, detail="OpenAI API key not configured")
    
    try:
        client = AsyncOpenAI(api_key=OPENAI_API_KEY)
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å¤‰æ•°ã§ç½®æ›
        system_prompt = template.system_prompt
        for var_name, var_value in request.variables.items():
            placeholder = f"{{{var_name}}}"
            system_prompt = system_prompt.replace(placeholder, var_value)
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": request.user_message}
        ]
        
        import time
        start_time = time.time()
        
        response = await client.chat.completions.create(
            model=request.model,
            messages=messages,
            temperature=0.7,
            max_tokens=800
        )
        
        processing_time = int((time.time() - start_time) * 1000)
        
        return ChatResponse(
            content=response.choices[0].message.content,
            model=response.model,
            tokens_used=response.usage.total_tokens if response.usage else 0,
            processing_time_ms=processing_time,
            finish_reason=response.choices[0].finish_reason,
            metadata={
                "template_id": template_id,
                "template_name": template.name,
                "prompt_tokens": response.usage.prompt_tokens if response.usage else 0,
                "completion_tokens": response.usage.completion_tokens if response.usage else 0,
            }
        )
        
    except openai.AuthenticationError:
        raise HTTPException(status_code=401, detail="Invalid OpenAI API key")
    except openai.RateLimitError:
        raise HTTPException(status_code=429, detail="OpenAI API rate limit exceeded")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Template processing error: {str(e)}")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)